{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profitable App Profiles for the App Store and Google Play Markets\n",
    "---\n",
    "Find mobile app profiles that are profitable for the App Store and Google Play markets. We're working as data analysts for a company that builds Android and iOS mobile apps, and our job is to enable our team of developers to make data-driven decisions with respect to the kind of apps they build.\n",
    "\n",
    "At our company, we only build apps that are free to download and install, and our main source of revenue consists of in-app ads. This means that our revenue for any given app is mostly influenced by the number of users that use our app. Our goal for this project is to analyze data to help our developers understand what kinds of apps are likely to attract more users.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['App', 'Category', 'Rating', 'Reviews', 'Size', 'Installs', 'Type', 'Price', 'Content Rating', 'Genres', 'Last Updated', 'Current Ver', 'Android Ver']\n",
      "['id', 'track_name', 'size_bytes', 'currency', 'price', 'rating_count_tot', 'rating_count_ver', 'user_rating', 'user_rating_ver', 'ver', 'cont_rating', 'prime_genre', 'sup_devices.num', 'ipadSc_urls.num', 'lang.num', 'vpp_lic']\n"
     ]
    }
   ],
   "source": [
    "from csv import reader\n",
    "\n",
    "### The Google Play data set ###\n",
    "opened_file = open('googleplaystore.csv', encoding='UTF-8')\n",
    "read_file = reader(opened_file)\n",
    "android = list(read_file)\n",
    "android_header = android[0]\n",
    "android = android[1:]\n",
    "\n",
    "### The App Store data set ###\n",
    "opened_file = open('AppleStore.csv', encoding='UTF-8')\n",
    "read_file = reader(opened_file)\n",
    "ios = list(read_file)\n",
    "ios_header = ios[0]\n",
    "ios = ios[1:]\n",
    "\n",
    "### Printing Each Header to determine what the values of each column indicate ###\n",
    "print(android_header)\n",
    "print(ios_header)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_data(dataset, start, end, rows_and_columns=False):\n",
    "    dataset_slice = dataset[start:end]    \n",
    "    for row in dataset_slice:\n",
    "        print(row)\n",
    "        print('\\n') # adds a new (empty) line between rows\n",
    "        \n",
    "    if rows_and_columns:\n",
    "        print('Number of rows:', len(dataset))\n",
    "        print('Number of columns:', len(dataset[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['284882215', 'Facebook', '389879808', 'USD', '0.0', '2974676', '212', '3.5', '3.5', '95.0', '4+', 'Social Networking', '37', '1', '29', '1']\n",
      "\n",
      "\n",
      "['389801252', 'Instagram', '113954816', 'USD', '0.0', '2161558', '1289', '4.5', '4.0', '10.23', '12+', 'Photo & Video', '37', '0', '29', '1']\n",
      "\n",
      "\n",
      "Number of rows: 7197\n",
      "Number of columns: 16\n"
     ]
    }
   ],
   "source": [
    "explore_data(ios,0,2,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Photo Editor & Candy Camera & Grid & ScrapBook', 'ART_AND_DESIGN', '4.1', '159', '19M', '10,000+', 'Free', '0', 'Everyone', 'Art & Design', 'January 7, 2018', '1.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['Coloring book moana', 'ART_AND_DESIGN', '3.9', '967', '14M', '500,000+', 'Free', '0', 'Everyone', 'Art & Design;Pretend Play', 'January 15, 2018', '2.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "Number of rows: 10841\n",
      "Number of columns: 13\n"
     ]
    }
   ],
   "source": [
    "explore_data(android,0,2,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Clearing Corrupted Data\n",
    "\n",
    "__Corrupted Data__\n",
    "\n",
    "It is essential that all the data in the `csv` file is consistant. A single row that has different format from the rest of the data will alter the result.\n",
    "\n",
    "Following Dataset for google had corrupted data at index `android[10472]` The following Data had one less column than other datasets which could lead to our desired result becoming corrupt.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Life Made WI-Fi Touchscreen Photo Frame', '1.9', '19', '3.0M', '1,000+', 'Free', '0', 'Everyone', '', 'February 11, 2018', '1.0.19', '4.0 and up']\n",
      "Columns:  12\n",
      "['Photo Editor & Candy Camera & Grid & ScrapBook', 'ART_AND_DESIGN', '4.1', '159', '19M', '10,000+', 'Free', '0', 'Everyone', 'Art & Design', 'January 7, 2018', '1.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['Coloring book moana', 'ART_AND_DESIGN', '3.9', '967', '14M', '500,000+', 'Free', '0', 'Everyone', 'Art & Design;Pretend Play', 'January 15, 2018', '2.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "Number of rows: 10840\n",
      "Number of columns: 13\n"
     ]
    }
   ],
   "source": [
    "print(android[10472])\n",
    "print('Columns: ', len(android[10472]))\n",
    "\n",
    "del android[10472]\n",
    "explore_data(android,0,2,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Duplicate Data\n",
    "\n",
    "__Part One__\n",
    "___\n",
    "\n",
    "Checking dataset for duplicates and coming up with the criterion for duplicate elimination can result in more accurate result/prediction\n",
    "\n",
    "Once corrup data has been removed from the dataset, Two lists need to be created in order to sort the duplicate datasets.\n",
    "`unique_apps` and `duplicate_apps`. `unique_apps` will store one of each app names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9659\n",
      "1181\n"
     ]
    }
   ],
   "source": [
    "unique_apps   = []\n",
    "duplicate_apps= []\n",
    "\n",
    "for app in android:\n",
    "    if app[0] in unique_apps:\n",
    "        duplicate_apps.append(app[0])\n",
    "    else:\n",
    "        unique_apps.append(app[0])\n",
    "\n",
    "print(len(unique_apps))\n",
    "print(len(duplicate_apps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "There are in total `1181` Duplicate Data sets.\n",
    "In order to fully utilize the datasets, removing duplicates randomly will reduce the result/predictions due to the fact that each of the duplicate rows have different number of reviews.\n",
    "\n",
    "Unlike android List, ios list does not contain duplicate data as displayed above and thus only the duplicate lists in android dataset needs to be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "ios_unique_apps   = []\n",
    "ios_duplicate_apps= []\n",
    "\n",
    "for app in ios:\n",
    "    if app[0] in ios_unique_apps:\n",
    "        ios_duplicate_apps.append(app[0])\n",
    "    else:\n",
    "        ios_unique_apps.append(app[0])\n",
    "\n",
    "print(len(ios_duplicate_apps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Part Two__\n",
    "\n",
    "Since we have decided that the number of reviews is an important factor, it would be reasonable to keep the row with highest value of reviews from the duplicate list.\n",
    "\n",
    "In order to accomplish that, I've created map that consists of each __app name__ as `key` and __reviews__ as `val`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Photo Editor & Candy Camera & Grid & ScrapBook', 'ART_AND_DESIGN', '4.1', '159', '19M', '10,000+', 'Free', '0', 'Everyone', 'Art & Design', 'January 7, 2018', '1.0.0', '4.0.3 and up']\n"
     ]
    }
   ],
   "source": [
    "print(android[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_reviews = {}\n",
    "\n",
    "for app in android:\n",
    "    name = app[0]\n",
    "    reviews = float(app[3])\n",
    "    \n",
    "    if name in max_reviews and max_reviews[name] < reviews:\n",
    "        max_reviews[name] = reviews\n",
    "    elif name not in max_reviews:\n",
    "        max_reviews[name] = reviews\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This process should have created a dictionary with max reviews of all the apps without duplicates\n",
    "In order to check if the following the length of the dictionary should equal to the length of `android` excluding the duplicates which is `1181`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_reviews Length :  9659\n",
      "android list without dup :  9659\n"
     ]
    }
   ],
   "source": [
    "print('max_reviews Length : ',len(max_reviews))\n",
    "print('android list without dup : ', len(android)-1181)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As Seen above, dictionary without duplicates has been created, now in order to remove the duplicates from `android` list, simply initialize an empty list to store final data\n",
    "\n",
    "We loop through the android data set, and for every iteration:\n",
    "   - We isolate the name of the app and the number of reviews.\n",
    "   - We add the current row (app) to the android_clean list, and the app name (name) to the already_added list if:\n",
    "        - The number of reviews of the current app matches the number of reviews of that app as described in the `reviews_max` dictionary; and The name of the app is not already in the `already_added` list. We need to add this supplementary condition to account for those cases where the highest number of reviews of a duplicate app is the same for more than one entry (for example, the 'Box app' has three entries, and the number of reviews is the same). If we just check for `reviews_max[name] == n_reviews`, we'll still end up with duplicate entries for some apps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9659\n",
      "[['Photo Editor & Candy Camera & Grid & ScrapBook', 'ART_AND_DESIGN', '4.1', '159', '19M', '10,000+', 'Free', '0', 'Everyone', 'Art & Design', 'January 7, 2018', '1.0.0', '4.0.3 and up'], ['U Launcher Lite – FREE Live Cool Themes, Hide Apps', 'ART_AND_DESIGN', '4.7', '87510', '8.7M', '5,000,000+', 'Free', '0', 'Everyone', 'Art & Design', 'August 1, 2018', '1.2.4', '4.0.3 and up']]\n"
     ]
    }
   ],
   "source": [
    "final_android = []\n",
    "already_added = []\n",
    "\n",
    "for app in android:\n",
    "    name = app[0]\n",
    "    review = float(app[3])\n",
    "    \n",
    "    if (max_reviews[name] == review) and (name not in already_added):\n",
    "        final_android.append(app)\n",
    "        already_added.append(name)\n",
    "        \n",
    "print(len(final_android))\n",
    "print(final_android[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Removing Non-English Apps\n",
    "\n",
    "__Part One__\n",
    "\n",
    "Each list contains apps that are not in English, though it is not a necessity, in this case we will remove non english apps from the list\n",
    "\n",
    "In order to accomplish the task, any character that is above 127 in ascii chart is considered non-english, but there is a flaw in using the following standard.\n",
    "\n",
    "   - Emoticons have high ASCII numbers\n",
    "   - Certain characters that are not non-english can also be above 127 in the ascii chart (ex. ™)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_english(string):\n",
    "    for chars in string:\n",
    "        if ord(chars) > 127:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English App:  9117\n",
      "Non-Eng App:  542\n"
     ]
    }
   ],
   "source": [
    "tmp_n_eng = []\n",
    "tmp_eng = []\n",
    "\n",
    "for app in final_android:\n",
    "    if is_english(app[0]):\n",
    "        tmp_eng.append(app[0])\n",
    "    else:\n",
    "        tmp_n_eng.append(app[0])\n",
    "        \n",
    "print('English App: ', len(tmp_eng))\n",
    "print('Non-Eng App: ', len(tmp_n_eng))\n",
    "# print(tmp_n_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_english(string):\n",
    "    non_ascii = 0\n",
    "    \n",
    "    for chars in string:\n",
    "        if ord(chars) > 127:\n",
    "            non_ascii += 1\n",
    "            \n",
    "    if non_ascii > 3:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English App:  9614\n",
      "Non-Eng App:  45\n"
     ]
    }
   ],
   "source": [
    "tmp_n_eng = []\n",
    "tmp_eng = []\n",
    "\n",
    "for app in final_android:\n",
    "    if is_english(app[0]):\n",
    "        tmp_eng.append(app[0])\n",
    "    else:\n",
    "        tmp_n_eng.append(app[0])\n",
    "        \n",
    "print('English App: ', len(tmp_eng))\n",
    "print('Non-Eng App: ', len(tmp_n_eng))\n",
    "# print(tmp_n_eng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, replacing any apps that contain ASCII Characters that are above 127 will reduce the dataset by `542` as opposed to setting a limit for number of characters that are above certain ASCII character will reduce the data loss.\n",
    "\n",
    "Using the custom function to filter out the app titles of each dataset, we can filter out __English__ apps and __Non-English__ apps for android and ios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eng Android App:  9614\n",
      "Eng ios App:  6183\n"
     ]
    }
   ],
   "source": [
    "android_eng = []\n",
    "ios_eng = []\n",
    "\n",
    "for app in final_android:\n",
    "    if is_english(app[0]):\n",
    "        android_eng.append(app)\n",
    "\n",
    "for app in ios:\n",
    "    if is_english(app[1]):\n",
    "        ios_eng.append(app)\n",
    "        \n",
    "print('Eng Android App: ', len(android_eng))\n",
    "print('Eng ios App: ', len(ios_eng))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolating Free Apps\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8864\n",
      "3222\n"
     ]
    }
   ],
   "source": [
    "android_final = []\n",
    "ios_final = []\n",
    "\n",
    "for app in android_eng:\n",
    "    price = app[7]\n",
    "    if price == '0':\n",
    "        android_final.append(app)\n",
    "    \n",
    "    \n",
    "for app in ios_eng:\n",
    "    price = app[4]\n",
    "    if price == '0.0':\n",
    "        ios_final.append(app)\n",
    "        \n",
    "        \n",
    "print(len(android_final))\n",
    "print(len(ios_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most common apps by Genre\n",
    "\n",
    "The purpose of the project was to finding out what kind of apps are appealing to the general users and to come up with a strategy  that will maximize the profitability.\n",
    "\n",
    "In order to accomplish our goal we will be analyzing the `prime_genre` of app store dataset and `Genres` and `Category` columns of the Google Play Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_table(dataset, index):\n",
    "    table = {}\n",
    "    total = 0\n",
    "    \n",
    "    for app in dataset:\n",
    "        total += 1\n",
    "        value = app[index]\n",
    "        \n",
    "        if value in table:\n",
    "            table[value] += 1\n",
    "        else:\n",
    "            table[value] = 1\n",
    "    \n",
    "    table_percentage = {}\n",
    "    \n",
    "    for key in table:\n",
    "        percentage = (table[key]/total)*100\n",
    "        table_percentage[key] = percentage\n",
    "    \n",
    "    return table_percentage\n",
    "\n",
    "def display_table(dataset, index):\n",
    "    table = freq_table(dataset, index)\n",
    "    table_display = []\n",
    "    \n",
    "    for key in table:\n",
    "        key_val_tuple = (table[key], key)\n",
    "        table_display.append(key_val_tuple)\n",
    "        \n",
    "    table_sorted = sorted(table_display, reverse = True)\n",
    "    for entry in table_sorted:\n",
    "        print(entry[1], ':', entry[0])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by examining the frequency table for the `prime_genre` column of the App Store data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Games : 58.16263190564867\n",
      "Entertainment : 7.883302296710118\n",
      "Photo & Video : 4.9658597144630665\n",
      "Education : 3.662321539416512\n",
      "Social Networking : 3.2898820608317814\n",
      "Shopping : 2.60707635009311\n",
      "Utilities : 2.5139664804469275\n",
      "Sports : 2.1415270018621975\n",
      "Music : 2.0484171322160147\n",
      "Health & Fitness : 2.0173805090006205\n",
      "Productivity : 1.7380509000620732\n",
      "Lifestyle : 1.5828677839851024\n",
      "News : 1.3345747982619491\n",
      "Travel : 1.2414649286157666\n",
      "Finance : 1.1173184357541899\n",
      "Weather : 0.8690254500310366\n",
      "Food & Drink : 0.8069522036002483\n",
      "Reference : 0.5586592178770949\n",
      "Business : 0.5276225946617008\n",
      "Book : 0.4345127250155183\n",
      "Navigation : 0.186219739292365\n",
      "Medical : 0.186219739292365\n",
      "Catalogs : 0.12414649286157665\n"
     ]
    }
   ],
   "source": [
    "display_table(ios_final, -5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
