{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hacker News Analysis By Popularity\n",
    "\n",
    "In this project, we'll compare two different types of posts from [Hacker News]('https://news.ycombinator.com/'), a popular site where technology related stories(or 'posts') are voted and commented upon. The two types of posts we'll explore begin with either `Ask HN` or `Show HN`.\n",
    "\n",
    "Users submit `Ask HN` posts to ask the Hacker News community a specific question, such as \"What is the best online course you've ever taken?\" Likewise, users submit `Show HN` posts to show the Hacker News Community a project, product, or just generally something interesting.\n",
    "\n",
    "We'll specifically compares these two types of posts to determine the following:\n",
    "\n",
    "- Do `Ask HN` or `Show HN` receive more comments on average?\n",
    "- Do posts created at a certain time receive more comments on average?\n",
    "\n",
    "**The Following Dataset was reduced from 300,000 to 20,000 rows for removing all submissions that did not receive any comments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'], ['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52']]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "file = open('hacker_news.csv', encoding = 'utf-8')\n",
    "\n",
    "read_file = csv.reader(file)\n",
    "\n",
    "hn = list(read_file)\n",
    "\n",
    "print(hn[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with any other machine learning projects, we'll first remove the header from the read file for the sake easing the process of iterating through the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "--------------------------------------------------------\n",
      "\n",
      "[['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01'], ['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']]\n"
     ]
    }
   ],
   "source": [
    "hn_header = hn[0]\n",
    "hn = hn[1:]\n",
    "\n",
    "print(hn_header)\n",
    "print('\\n--------------------------------------------------------\\n')\n",
    "print(hn[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Ask HN and Show HN Posts\n",
    "\n",
    "Now that the header and dataset has been sorted, loop through the dataset to look for posts that start with `Ask HN` or `Show HN`.\n",
    "\n",
    "**※The Following dataset can be classifieid by the title, the beginning ask post starts with `Ask HN` and show posts starting with `Show HN` while the remainder does not have such classifier※**\n",
    "\n",
    "This can be achieved by using two in built methods of python, `lower` and `startswith()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask_Posts Length:  1744\n",
      "Show_Posts Length:  1162\n",
      "Other_Posts length:  17194\n",
      "\n",
      " -------------------------------- \n",
      "\n",
      "['12296411', 'Ask HN: How to improve my personal website?', '', '2', '6', 'ahmedbaracat', '8/16/2016 9:55']\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    title = title.lower()\n",
    "    if title.startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "        \n",
    "print('Ask_Posts Length: ', len(ask_posts))\n",
    "print('Show_Posts Length: ', len(show_posts))\n",
    "print('Other_Posts length: ', len(other_posts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that posts that classify as `Ask HN`, `Show HN` and `Other` has been sorted, we can loop through each of the category to see how many comments have been set on each category to determine which category is more popular amongst the posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total Ask HN has total of 24483 comments and avg of 14.04 comments\n",
      "In total Show HN has total of 11988 comments and avg of 10.32 comments\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "total_show_comments = 0\n",
    "avg_ask_comment = 0\n",
    "avg_show_comment = 0\n",
    "\n",
    "for row in ask_posts:\n",
    "    total_ask_comments += int(row[4])\n",
    "    \n",
    "for row in show_posts:\n",
    "    total_show_comments += int(row[4])\n",
    "\n",
    "avg_ask_comment = total_ask_comments / len(ask_posts)\n",
    "avg_show_comment = total_show_comments / len(show_posts)\n",
    "\n",
    "print('In total {tab} has total of {tot} comments and avg of {avg:.2f} comments'.format(tab = 'Ask HN', tot = total_ask_comments, avg = avg_ask_comment))\n",
    "print('In total {tab} has total of {tot} comments and avg of {avg:.2f} comments'.format(tab = 'Show HN', tot = total_show_comments, avg = avg_show_comment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As Shown as the result above, `Ask HN` posts have on average `4%` more than `Show HN` posts. As such, we'll be focusing on the more popular `Ask HN` posts for the remaining analysis.*(Will be making further analysis on the less popular `Show HN` Posts)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
