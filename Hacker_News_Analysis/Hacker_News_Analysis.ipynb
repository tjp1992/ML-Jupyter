{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hacker News Analysis By Popularity\n",
    "\n",
    "In this project, we'll compare two different types of posts from [Hacker News]('https://news.ycombinator.com/'), a popular site where technology related stories(or 'posts') are voted and commented upon. The two types of posts we'll explore begin with either `Ask HN` or `Show HN`.\n",
    "\n",
    "Users submit `Ask HN` posts to ask the Hacker News community a specific question, such as \"What is the best online course you've ever taken?\" Likewise, users submit `Show HN` posts to show the Hacker News Community a project, product, or just generally something interesting.\n",
    "\n",
    "We'll specifically compares these two types of posts to determine the following:\n",
    "\n",
    "- Do `Ask HN` or `Show HN` receive more comments on average?\n",
    "- Do posts created at a certain time receive more comments on average?\n",
    "\n",
    "**The Following Dataset was reduced from 300,000 to 20,000 rows for removing all submissions that did not receive any comments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'], ['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52']]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "file = open('hacker_news.csv', encoding = 'utf-8')\n",
    "\n",
    "read_file = csv.reader(file)\n",
    "\n",
    "hn = list(read_file)\n",
    "\n",
    "print(hn[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with any other machine learning projects, we'll first remove the header from the read file for the sake easing the process of iterating through the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "--------------------------------------------------------\n",
      "\n",
      "[['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01'], ['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']]\n"
     ]
    }
   ],
   "source": [
    "hn_header = hn[0]\n",
    "hn = hn[1:]\n",
    "\n",
    "print(hn_header)\n",
    "print('\\n--------------------------------------------------------\\n')\n",
    "print(hn[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Ask HN and Show HN Posts\n",
    "\n",
    "Now that the header and dataset has been sorted, loop through the dataset to look for posts that start with `Ask HN` or `Show HN`.\n",
    "\n",
    "**※The Following dataset can be classifieid by the title, the beginning ask post starts with `Ask HN` and show posts starting with `Show HN` while the remainder does not have such classifier※**\n",
    "\n",
    "This can be achieved by using two in built methods of python, `lower` and `startswith()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask_Posts Length:  1744\n",
      "Show_Posts Length:  1162\n",
      "Other_Posts length:  17194\n",
      "\n",
      " -------------------------------- \n",
      "\n",
      "['12296411', 'Ask HN: How to improve my personal website?', '', '2', '6', 'ahmedbaracat', '8/16/2016 9:55']\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    title = title.lower()\n",
    "    if title.startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "        \n",
    "print('Ask_Posts Length: ', len(ask_posts))\n",
    "print('Show_Posts Length: ', len(show_posts))\n",
    "print('Other_Posts length: ', len(other_posts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that posts that classify as `Ask HN`, `Show HN` and `Other` has been sorted, we can loop through each of the category to see how many comments have been set on each category to determine which category is more popular amongst the posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total Ask HN has total of 24483 comments and avg of 14.04 comments\n",
      "In total Show HN has total of 11988 comments and avg of 10.32 comments\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "total_show_comments = 0\n",
    "avg_ask_comment = 0\n",
    "avg_show_comment = 0\n",
    "\n",
    "for row in ask_posts:\n",
    "    total_ask_comments += int(row[4])\n",
    "    \n",
    "for row in show_posts:\n",
    "    total_show_comments += int(row[4])\n",
    "\n",
    "avg_ask_comment = total_ask_comments / len(ask_posts)\n",
    "avg_show_comment = total_show_comments / len(show_posts)\n",
    "\n",
    "print('In total {tab} has total of {tot} comments and avg of {avg:.2f} comments'.format(tab = 'Ask HN', tot = total_ask_comments, avg = avg_ask_comment))\n",
    "print('In total {tab} has total of {tot} comments and avg of {avg:.2f} comments'.format(tab = 'Show HN', tot = total_show_comments, avg = avg_show_comment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As Shown as the result above, `Ask HN` posts have on average `4%` more than `Show HN` posts. As such, we'll be focusing on the more popular `Ask HN` posts for the remaining analysis.*(Will be making further analysis on the less popular `Show HN` Posts)*\n",
    "\n",
    "## Finding the Amount of Ask Posts and Comments by Hour Created\n",
    "\n",
    "We'll be making additional analysis on `Ask HN` Dataset by determining at which specific time of the day will attract more comments. As such following steps will be used to perform this analysis:\n",
    "\n",
    "- Calculate the number of ask posts created in each hour of the day, along with the number of comments received.\n",
    "- Calculate the average number of comments ask posts receive by hour created.\n",
    "\n",
    "The first step can be achieved by calculating the number of Ask posts and comments by hour created. we'll use `datetime` module to work with the data in the `created_at` column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00 : 447\n",
      "01 : 683\n",
      "02 : 1381\n",
      "03 : 421\n",
      "04 : 337\n",
      "05 : 464\n",
      "06 : 397\n",
      "07 : 267\n",
      "08 : 492\n",
      "09 : 251\n",
      "10 : 793\n",
      "11 : 641\n",
      "12 : 687\n",
      "13 : 1253\n",
      "14 : 1416\n",
      "15 : 4477\n",
      "16 : 1814\n",
      "17 : 1146\n",
      "18 : 1439\n",
      "19 : 1188\n",
      "20 : 1722\n",
      "21 : 1745\n",
      "22 : 479\n",
      "23 : 543\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "result_list = []\n",
    "\n",
    "for row in ask_posts:\n",
    "    result_list.append([row[6], int(row[4])])\n",
    "\n",
    "comments_by_hour = {}\n",
    "counts_by_hour = {}\n",
    "date_format = '%m/%d/%Y %H:%M'\n",
    "\n",
    "for row in result_list:\n",
    "    date = row[0]\n",
    "    comment = row[1]\n",
    "    time = dt.datetime.strptime(date, date_format).strftime('%H')\n",
    "    if time in counts_by_hour:\n",
    "        counts_by_hour[time] += 1\n",
    "        comments_by_hour[time] += comment\n",
    "    else:\n",
    "        counts_by_hour[time] = 1\n",
    "        comments_by_hour[time] = comment\n",
    "\n",
    "        \n",
    "for key in sorted(comments_by_hour.keys()):\n",
    "    print(key, ':', comments_by_hour[key])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As Displayed above, comments by hour has been sorted and as shown by the result, there was a slight spike at `2 am` but the spike cluster is mostly between the hours of `1 pm` to `9 pm`, reaching the max at `3 pm`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the Average Number of Comments for Ask HN Posts by Hour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['09', 5.5777777777777775],\n",
       " ['13', 14.741176470588234],\n",
       " ['10', 13.440677966101696],\n",
       " ['14', 13.233644859813085],\n",
       " ['16', 16.796296296296298],\n",
       " ['23', 7.985294117647059],\n",
       " ['12', 9.41095890410959],\n",
       " ['17', 11.46],\n",
       " ['15', 38.5948275862069],\n",
       " ['21', 16.009174311926607],\n",
       " ['20', 21.525],\n",
       " ['02', 23.810344827586206],\n",
       " ['18', 13.20183486238532],\n",
       " ['03', 7.796296296296297],\n",
       " ['05', 10.08695652173913],\n",
       " ['19', 10.8],\n",
       " ['01', 11.383333333333333],\n",
       " ['22', 6.746478873239437],\n",
       " ['08', 10.25],\n",
       " ['04', 7.170212765957447],\n",
       " ['00', 8.127272727272727],\n",
       " ['06', 9.022727272727273],\n",
       " ['07', 7.852941176470588],\n",
       " ['11', 11.051724137931034]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "\n",
    "for key in comments_by_hour:\n",
    "    avg_by_hour.append([key,comments_by_hour[key]/counts_by_hour[key]])\n",
    "\n",
    "avg_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting and Printing Values from a List of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[38.5948275862069, '15'],\n",
       " [23.810344827586206, '02'],\n",
       " [21.525, '20'],\n",
       " [16.796296296296298, '16'],\n",
       " [16.009174311926607, '21'],\n",
       " [14.741176470588234, '13'],\n",
       " [13.440677966101696, '10'],\n",
       " [13.233644859813085, '14'],\n",
       " [13.20183486238532, '18'],\n",
       " [11.46, '17'],\n",
       " [11.383333333333333, '01'],\n",
       " [11.051724137931034, '11'],\n",
       " [10.8, '19'],\n",
       " [10.25, '08'],\n",
       " [10.08695652173913, '05'],\n",
       " [9.41095890410959, '12'],\n",
       " [9.022727272727273, '06'],\n",
       " [8.127272727272727, '00'],\n",
       " [7.985294117647059, '23'],\n",
       " [7.852941176470588, '07'],\n",
       " [7.796296296296297, '03'],\n",
       " [7.170212765957447, '04'],\n",
       " [6.746478873239437, '22'],\n",
       " [5.5777777777777775, '09']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1], row[0]])\n",
    "\n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse = True)\n",
    "sorted_swap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for 'Ask HN' Comments\n",
      "15:00 : 38.59 average comments per post\n",
      "02:00 : 23.81 average comments per post\n",
      "20:00 : 21.52 average comments per post\n",
      "16:00 : 16.80 average comments per post\n",
      "21:00 : 16.01 average comments per post\n"
     ]
    }
   ],
   "source": [
    "template = '{time} : {avg:.2f} average comments per post'\n",
    "print(\"Top 5 Hours for 'Ask HN' Comments\")\n",
    "\n",
    "for avg,hr in sorted_swap[:5]:\n",
    "        print(template.format(time = dt.datetime.strptime(hr, '%H').strftime('%H:%M'),avg = avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Hour that received the most comment per post on average is 15:00, with an average of 38.59 comments per post. There's about 60% increase in the number of comments between the hours with the highest and second highest average number of comments.\n",
    "\n",
    "According to the data set [documentation]('https://www.kaggle.com/hacker-news/hacker-news-posts/home'), the timezone used in Eastern Time in the US. So, we could write 15:00 as 3:00 pm est."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this project, we analyzed `Ask HM` and `Show HM` posts to determine which type of post and time received the most comments on average. Based on our analysis, to maximize the amount of comments a post reviews, we'd recommend the post be categorized as `Ask Post` and created between 15:00 and 16:00.\n",
    "\n",
    "However, it should be noted that the dataset we analyzed excluded posts without any comments. Given that, it's more accurate to say that *of the posts that received comments,* ask posts received more comments on average and ask posts created between 15:00 and 16:00 received the most comments on average."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
